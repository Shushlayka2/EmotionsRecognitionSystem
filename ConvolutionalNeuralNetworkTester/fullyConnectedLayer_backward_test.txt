void FullyConnectedLayer::backward(float* prev_layer_gradients) {

	//mock
	in_size = 5; out_size = 3;
	float* weights_host = new float[out_size * in_size];
	float* outputs_host = new float[out_size];
	float* inputs_host = new float[in_size];
	float* gradients_host = new float[out_size];
	for (int i = 0; i < out_size * in_size; i++)
		weights_host[i] = i;
	for (int i = 0; i < out_size; i++)
		outputs_host[i] = i;
	for (int i = 0; i < in_size; i++)
		inputs_host[i] = i;
	for (int i = 0; i < out_size; i++)
		gradients_host[i] = i;
	cudaMemcpy(weights_device, weights_host, out_size * in_size * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(outputs_device, outputs_host, out_size * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(inputs_device, inputs_host, in_size * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(gradients_device, gradients_host, out_size * sizeof(float), cudaMemcpyHostToDevice);
	free(outputs_host);
	free(inputs_host);
	free(weights_host);
	free(gradients_host);
	
	m_v_multiplication(weights_device, gradients_device, prev_layer_gradients, handle, CUBLAS_OP_N);
	
	//assert
	gradients_host = new float[in_size];
	cudaMemcpy(gradients_host, prev_layer_gradients, in_size * sizeof(float), cudaMemcpyDeviceToHost);
	for (int i = 0; i < in_size; i++)
		printf("%f ", gradients_host[i]);
	printf("\n");

	dim3 threadsPerBlock = BLOCK_SIZE;
	dim3 blocksPerGrid = in_size / BLOCK_SIZE + (in_size % BLOCK_SIZE == 0 ? 0 : 1);
	cudaBindTexture(0, InputsRef, inputs_device, in_size * sizeof(float));
	cudaBindTexture(0, GradientsRef, gradients_device, out_size * sizeof(float));

	cuda_gr_to_der_mult << <blocksPerGrid, threadsPerBlock >> > (prev_layer_gradients, in_size);
	cudaDeviceSynchronize();
	cudacall(cudaGetLastError());

	//assert
	cudaMemcpy(gradients_host, prev_layer_gradients, in_size * sizeof(float), cudaMemcpyDeviceToHost);
	for (int i = 0; i < in_size; i++)
		printf("%f ", gradients_host[i]);
	printf("\n");

	correct();

	cudaUnbindTexture(InputsRef);
	cudaUnbindTexture(GradientsRef);
}

void FullyConnectedLayer::correct() {
	
	dim3 threadsPerBlock = dim3(DOUBLE_BLOCK_SIZE, DOUBLE_BLOCK_SIZE);
	dim3 blocksPerGrid = dim3(in_size / DOUBLE_BLOCK_SIZE + (in_size % DOUBLE_BLOCK_SIZE == 0 ? 0 : 1),
		out_size / DOUBLE_BLOCK_SIZE + (out_size % DOUBLE_BLOCK_SIZE == 0 ? 0 : 1));
	
	cuda_correct_weights << <blocksPerGrid, threadsPerBlock >> > (weights_device, in_size, out_size);
	cudaDeviceSynchronize();
	cudacall(cudaGetLastError());

	//assert
	float* weights_host = new float[in_size * out_size];
	cudaMemcpy(weights_host, weights_device, in_size * out_size * sizeof(float), cudaMemcpyDeviceToHost);
	for (int i = 0; i < out_size; i++)
	{
		for (int j = 0; j < in_size; j++)
		{
			printf("%f ", weights_host[i * in_size + j]);
		}
		printf("\n");
	}
	printf("\n");
	free(weights_host);
	
	threadsPerBlock = BLOCK_SIZE;
	blocksPerGrid = out_size / BLOCK_SIZE + (out_size % BLOCK_SIZE == 0 ? 0 : 1);
	cuda_correct_biases << <blocksPerGrid, threadsPerBlock >> > (biases_device, out_size);
	cudaDeviceSynchronize();
	cudacall(cudaGetLastError());

	//assert
	float* biases_host = new float[out_size];
	cudaMemcpy(biases_host, biases_device, out_size * sizeof(float), cudaMemcpyDeviceToHost);
	for (int i = 0; i < out_size; i++)
		printf("%f ", biases_host[i]);
	printf("\n");
	free(biases_host);
}